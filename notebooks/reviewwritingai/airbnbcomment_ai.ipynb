{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "5oMXe3uNoS7I"
   },
   "outputs": [],
   "source": [
    "!pip install -q textgenrnn\n",
    "from google.colab import files\n",
    "from textgenrnn import textgenrnn\n",
    "from datetime import datetime\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "Ax78skAMoVR4"
   },
   "outputs": [],
   "source": [
    "model_cfg = {\n",
    "    'word_level': False,   # set to True if want to train a word-level model (requires more data and smaller max_length)\n",
    "    'rnn_size': 128,   # number of LSTM cells of each layer (128/256 recommended)\n",
    "    'rnn_layers': 3,   # number of LSTM layers (>=2 recommended)\n",
    "    'rnn_bidirectional': False,   # consider text both forwards and backward, can give a training boost\n",
    "    'max_length': 30,   # number of tokens to consider before predicting the next (20-40 for characters, 5-10 for words recommended)\n",
    "    'max_words': 10000,   # maximum number of words to model; the rest will be ignored (word-level model only)\n",
    "}\n",
    "\n",
    "train_cfg = {\n",
    "    'line_delimited': False,   # set to True if each text has its own line in the source file\n",
    "    'num_epochs': 10,   # set higher to train the model for longer\n",
    "    'gen_epochs': 2,   # generates sample text from model after given number of epochs\n",
    "    'train_size': 0.8,   # proportion of input data to train on: setting < 1.0 limits model from learning perfectly\n",
    "    'dropout': 0.0,   # ignore a random proportion of source tokens each epoch, allowing model to generalize better\n",
    "    'validation': False,   # If train__size < 1.0, test on holdout dataset; will make overall training slower\n",
    "    'is_csv': False   # set to True if file is a CSV exported from Excel/BigQuery/pandas\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "0aDjmkO3oWxo"
   },
   "outputs": [],
   "source": [
    "file_name = \"goodcomments.txt\"\n",
    "model_name = 'goodcomments'   # change to set file name of resulting trained models/texts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "KEkRZpVXonfZ"
   },
   "outputs": [],
   "source": [
    "textgen = textgenrnn(name=model_name)\n",
    "\n",
    "train_function = textgen.train_from_file if train_cfg['line_delimited'] else textgen.train_from_largetext_file\n",
    "\n",
    "train_function(\n",
    "    file_path=file_name,\n",
    "    new_model=True,\n",
    "    num_epochs=train_cfg['num_epochs'],\n",
    "    gen_epochs=train_cfg['gen_epochs'],\n",
    "    batch_size=1024,\n",
    "    train_size=train_cfg['train_size'],\n",
    "    dropout=train_cfg['dropout'],\n",
    "    validation=train_cfg['validation'],\n",
    "    is_csv=train_cfg['is_csv'],\n",
    "    rnn_layers=model_cfg['rnn_layers'],\n",
    "    rnn_size=model_cfg['rnn_size'],\n",
    "    rnn_bidirectional=model_cfg['rnn_bidirectional'],\n",
    "    max_length=model_cfg['max_length'],\n",
    "    dim_embeddings=100,\n",
    "    word_level=model_cfg['word_level'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "0RoA8EdGorAM"
   },
   "outputs": [],
   "source": [
    "# this temperature schedule cycles between 1 very unexpected token, 1 unexpected token, 2 expected tokens, repeat.\n",
    "# changing the temperature schedule can result in wildly different output!\n",
    "temperature = [1.0, 0.5, 0.2, 0.2]   \n",
    "prefix = None   # if you want each generated text to start with a given seed text\n",
    "\n",
    "if train_cfg['line_delimited']:\n",
    "  n = 1000\n",
    "  max_gen_length = 60 if model_cfg['word_level'] else 300\n",
    "else:\n",
    "  n = 1\n",
    "  max_gen_length = 2000 if model_cfg['word_level'] else 10000\n",
    "  \n",
    "timestring = datetime.now().strftime('%Y%m%d_%H%M%S')\n",
    "gen_file = '{}_gentext_{}.txt'.format(model_name, timestring)\n",
    "\n",
    "textgen.generate_to_file(gen_file,\n",
    "                         temperature=temperature,\n",
    "                         prefix=prefix,\n",
    "                         n=n,\n",
    "                         max_gen_length=max_gen_length)\n",
    "files.download(gen_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "mpiON4yLovQ7"
   },
   "outputs": [],
   "source": [
    "files.download('{}_weights.hdf5'.format(model_name))\n",
    "files.download('{}_vocab.json'.format(model_name))\n",
    "files.download('{}_config.json'.format(model_name))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "HuiW0wA4ozWl"
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "name": "bnbcomment_ai.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
